{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import json\n",
    "import tqdm\n",
    "import openai\n",
    "\n",
    "openai.api_key = # Entrez votre clef d'API openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find job ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui permet de récupérer les id des offres d'emploi Linkedin\n",
    "def makeUrl(params):\n",
    "    url = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?\"\n",
    "    for key, value in params.items():\n",
    "        if type(value) == str:\n",
    "            value = value.replace(\" \", \"%20\")\n",
    "        url += f\"{key}={value}&\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui boucle sur les pages de résultats pour récupérer les id des offres d'emploi Linkedin\n",
    "def get_job_ids(params, max_items, save_path):\n",
    "    \"\"\"\n",
    "    Save job ids to a json file\n",
    "    :param params: dictionary of parameters (keywords, location, geoId)\n",
    "    :param max_items: maximum number of items to retrieve\n",
    "    :param save_path: path to save the json file\n",
    "    \"\"\"\n",
    "\n",
    "    job_id_list = []\n",
    "    url = makeUrl(params)\n",
    "    # is_over = False\n",
    "    start = 0\n",
    "    while (start < max_items):\n",
    "        try:\n",
    "            res = requests.get(url + f\"start={start}\")\n",
    "            soup = BeautifulSoup(res.text, 'html.parser')\n",
    "            alljobs_on_this_page = soup.find_all(\"li\")\n",
    "            print(start, ':', len(alljobs_on_this_page))\n",
    "            for i in range(0, len(alljobs_on_this_page)):\n",
    "                try:\n",
    "                    jobid = alljobs_on_this_page[i].find(\n",
    "                        \"div\", {\"class\": \"base-card\"}).get('data-entity-urn').split(\":\")[3]\n",
    "                    job_id_list.append(jobid)\n",
    "                except:\n",
    "                    is_over = True\n",
    "                    break\n",
    "            start += 25\n",
    "        except:\n",
    "            break\n",
    "    job_id_list = list(set(job_id_list))\n",
    "    print(f\"Total job ids: {len(job_id_list)}\")\n",
    "    json_doc = {\n",
    "        \"keywords\": params[\"keywords\"],\n",
    "        \"location\": params[\"location\"],\n",
    "        \"geoId\": params[\"geoId\"],\n",
    "        \"job_id_list\": job_id_list\n",
    "    }\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_doc, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the job ids in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=developpeur%20mobile&location=France&geoId=105015875&\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"keywords\": 'developpeur mobile',\n",
    "    \"location\": 'France',\n",
    "    \"geoId\": '105015875',\n",
    "}\n",
    "print(makeUrl(params))\n",
    "get_job_ids(params, 1000, \"scrapped_data/job_ids_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve jobs information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui permet de récupérer les informations sur une offre d'emploi Linkedin sous la forme d'un dictionnaire\n",
    "def get_job_information(job_id):\n",
    "    \"\"\"\n",
    "    Get job information from job id\n",
    "    :param job_id: job id\n",
    "    :return: dictionary of job information (company, job-title, location, posted, applicants, easy-apply, description)\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "    job_info = {}\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    # nom de l'entreprise\n",
    "    try:\n",
    "        job_info[\"company\"] = soup.find(\n",
    "            \"div\", {\"class\": \"top-card-layout__card\"}).find(\"a\").find(\"img\").get('alt')\n",
    "    except:\n",
    "        job_info[\"company\"] = None\n",
    "    # titre de l'annonce\n",
    "    try:\n",
    "        job_info[\"job-title\"] = soup.find(\n",
    "            \"div\", {\"class\": \"top-card-layout__entity-info\"}).find(\"a\").text.strip()\n",
    "    except:\n",
    "        job_info[\"job-title\"] = None\n",
    "\n",
    "    # infos sur le poste\n",
    "    try:\n",
    "        for item in soup.find(\"ul\", {\"class\": \"description__job-criteria-list\"}).find_all(\"li\"):\n",
    "            try:\n",
    "                key = item.find(\"h3\").text.strip()\n",
    "                value = item.find(\"span\").text.strip()\n",
    "                job_info[key] = value\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # description du poste\n",
    "    try:\n",
    "        job_info[\"description\"] = soup.find(\n",
    "            \"div\", {\"class\": \"show-more-less-html__markup\"}).text.strip()\n",
    "    except:\n",
    "        job_info[\"description\"] = None\n",
    "\n",
    "    return job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui permet de vérifier si une offre d'emploi est pertinente pour notre recherche (filtrage grossier)\n",
    "def is_job_relevant(job_info):\n",
    "    \"\"\"\n",
    "    Check if job is relevant\n",
    "    :param job_info: dictionary of job information\n",
    "    :return: True if job is relevant, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    if job_info[\"job-title\"] is None or job_info[\"description\"] is None:\n",
    "        return False\n",
    "    keywords = [' natif', ' native', ' hybrid', ' android', ' ios', 'kotlin', 'swift', 'flutter', 'react-native','react native', 'xamarin', 'ionic', 'java', 'objective-c', 'swiftui', 'react-native', 'swift', 'kotlin', 'flutter', 'xamarin', 'ionic', 'java', 'objective-c']\n",
    "    for key in keywords:\n",
    "        if key in job_info[\"description\"].lower() or key in job_info[\"job-title\"].lower():\n",
    "            # print(f\"Relevant job: {job_info['job-title']}\", \"keyword:\", key)\n",
    "            return True\n",
    "    # print(f\"Non-relevant job: {job_info['job-title']}\")\n",
    "    return False\n",
    "\n",
    "def checkpoint_save(job_info_dict, save_path):\n",
    "    \"\"\"\n",
    "    Save job information to a json file\n",
    "    :param job_info_dict: dictionary of job information\n",
    "    :param save_path: path to save the json file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(save_path, 'r', encoding='utf-8') as f:\n",
    "            jobs_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        jobs_data = {}\n",
    "\n",
    "    jobs_data.update(job_info_dict)\n",
    "\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(jobs_data, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def get_all_jobs_information(job_ids, save_path, current_data = {}, save_every=10, except_if_exists=True):\n",
    "    \"\"\"\n",
    "    Loop over job ids and get job information\n",
    "    :param job_ids: list of job ids\n",
    "    :param save_path: path to save the json file\n",
    "    :param current_data: dictionary of current job information\n",
    "    :param save_every: save every n items\n",
    "    :param except_if_exists: except if job id exists in current data, or overwrite\n",
    "    \"\"\"\n",
    "    job_info_dict = {}\n",
    "    for i, job_id in enumerate(tqdm.tqdm(job_ids)):\n",
    "        if except_if_exists and job_id in current_data and current_data[job_id] is not None:\n",
    "            continue\n",
    "        try:\n",
    "            job_info = get_job_information(job_id)\n",
    "            if not is_job_relevant(job_info):\n",
    "                job_info_dict[job_id] = None\n",
    "            else:\n",
    "                job_info_dict[job_id] = job_info\n",
    "            if (i + 1) % save_every == 0:\n",
    "                checkpoint_save(job_info_dict, save_path)\n",
    "                job_info_dict.clear()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job ID {job_id}: {e}\")\n",
    "    if job_info_dict:\n",
    "        checkpoint_save(job_info_dict, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve all job information and save it in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    current_data = json.load(open(\"scrapped_data/jobs_data_1.json\", 'r', encoding='utf-8'))\n",
    "except:\n",
    "    current_data = {}\n",
    "\n",
    "# list of all retrieved job ids\n",
    "job_ids = json.load(open(\"scrapped_data/job_ids_1.json\", 'r', encoding='utf-8')).get(\"job_id_list\") + json.load(open(\"scrapped_data/job_ids_2.json\", 'r', encoding='utf-8')).get(\"job_id_list\") + json.load(open(\"scrapped_data/job_ids_3.json\", 'r', encoding='utf-8')).get(\"job_id_list\")\n",
    "get_all_jobs_information(job_ids, 'scrapped_data/jobs_data_1.json', current_data, save_every=10, except_if_exists=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter jobs and extract technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import openai\n",
    "\n",
    "\n",
    "def generate_chatgpt_response(job_item):\n",
    "    \"\"\"\n",
    "    Generate response using chatgpt\n",
    "    :param job_item: job information\n",
    "    :return: response from chatgpt\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\":\n",
    "             \"\"\"Bonjour. je vais te donner des offres d'emploi linkedin de développement mobile. \n",
    "            Je veux que tu me dises s'il s'agit d'une offre pour du développement mobile natif (android ou ios), \n",
    "            sur framework hybride (ex flutter, react-native), si c'est du no-code (flutterflow, adalo, etc...), \n",
    "            si ce n'est pas précisé, \n",
    "            si plusieurs technologies sont possibles (natif ou hybride ou no code)\n",
    "            ou si c'est une offre qui ne concerne pas le développement mobile.\n",
    "            Ta réponse doit être au format suivant: {type_developpement}: {langages_et_frameworks_de_l'offre}\n",
    "            ou {type_developpement} est parmis ces mots: hybrid, native, nocode, unspecified, multiple, irrelevant.\n",
    "            et {langages_et_frameworks_de_l'offre} est une liste de langage ou frameworks de développement mobile UNIQUEMENT\n",
    "            à utiliser dans l'offre. (ex java, kotlin, swift, swiftui, flutter, react-native, xamarin, ionic, cordova, flutterflow...)\n",
    "            mais pas de PHP, python, C#, C++, etc...\n",
    "            Fait attention à bien classer ce qui n'est pas du développement mobile (développement web et logiciel) comme irrelevant.\n",
    "            Voici trois exemples de réponses:\n",
    "            \\n hybrid: flutter, react-native\n",
    "            \\n native: kotlin, swift\n",
    "            \\n irrelevant\n",
    "            \"\"\"},\n",
    "            {\"role\": \"assistant\",\n",
    "             \"content\": \"D'accord, je suis prêt. Vas-y, envoie-moi les offres d'emploi.\"},\n",
    "            {\"role\": \"user\", \"content\": str(job_item)}\n",
    "        ])\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def get_all_job_type(jobs_data, save_path, current_data={}, save_every=10, except_if_exists=True):\n",
    "    \"\"\"\n",
    "    Loop over job ids, extract job type and save to a json file\n",
    "    :param jobs_data: dictionary of job information\n",
    "    :param save_path: path to save the json file\n",
    "    :param current_data: dictionary of current job information\n",
    "    :param save_every: save every n items\n",
    "    :param except_if_exists: except if job id exists in current data, or overwrite\n",
    "    \"\"\"\n",
    "    job_type_dict = {}\n",
    "    for i, job_item in enumerate(tqdm.tqdm(jobs_data.items())):\n",
    "        job_id, job_data = job_item\n",
    "        if except_if_exists and job_id in current_data and current_data[job_id] is not None:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                job_data['type'] = generate_chatgpt_response(job_item)\n",
    "                job_type_dict[job_id] = job_data\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing job ID {job_id}: {e}\")\n",
    "        if (i + 1) % save_every == 0:\n",
    "            checkpoint_save(job_type_dict, save_path)\n",
    "            job_type_dict.clear()\n",
    "    if job_type_dict:\n",
    "        checkpoint_save(job_type_dict, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove null from data \n",
    "In the previous step, we have extracted the data from the job description.\\ The null values correspond to the job descriptions that are not available.\n",
    "\n",
    "We kept the null values because we wanted to remember the job ids that we could not retrieve the job description from, in case we had to loop over the data again. The algorithm as a parameter \"except_if_exists\" that check if the job id is already in the data if set to True. If it is, we skip the job id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('scrapped_data/jobs_data_1.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "filtered_data = {}\n",
    "for key, value in data.items():\n",
    "    if value is not None:\n",
    "        filtered_data[key] = value\n",
    "\n",
    "print(f'Original data: {len(data)}')\n",
    "print(f'Filtered data: {len(filtered_data)}')\n",
    "with open('scrapped_data/jobs_data_1_filtered.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(filtered_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data and Extract information with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [10:55<00:00,  1.22it/s] \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open(\"scrapped_data/jobs_data_1_filtered.json\", 'r', encoding='utf-8'))\n",
    "\n",
    "save_path = 'scrapped_data/data_gpt_2.json'\n",
    "\n",
    "try :\n",
    "    current_data = json.load(open(save_path, 'r', encoding='utf-8'))\n",
    "except:\n",
    "    current_data = {}\n",
    "\n",
    "get_all_job_type(data, save_path, current_data, save_every=10, except_if_exists=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the data to the desired format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('scrapped_data/data_gpt_2.json', encoding='utf-8') as f:\n",
    "    datagpt = json.load(f)\n",
    "\n",
    "# dictionnaire des mots clés pour chaque framework     \n",
    "keywords_dict = {\n",
    "    'flutter': ['flutter', 'dart'],\n",
    "    'react-native': ['react native', 'react-native', 'reactnative'],\n",
    "    'xamarin': ['xamarin'],\n",
    "    'ionic': ['ionic'],\n",
    "    'cordova': ['cordova'],\n",
    "    'kotlin': ['kotlin'],\n",
    "    'swift': ['swift'],\n",
    "    'objective-c': ['objective-c', 'objective c', 'objective_c', 'objectivec'],\n",
    "    'java': ['java.', 'java ', 'java,', 'java;', 'java:', 'java(', 'java)', 'java?', 'java!', 'java-', 'java_', 'java*', 'java/', 'java\\\\'],\n",
    "}\n",
    "filtered_datagpt = {}\n",
    "types = {}\n",
    "for key, value in datagpt.items():\n",
    "    \n",
    "    if value['type'] != 'irrelevant':\n",
    "        filtered_datagpt[key] = value\n",
    "        \n",
    "    item_type = value['type'].split(':')[0]\n",
    "    item_frameworks = \"\"\n",
    "    if ':' in value['type']:\n",
    "        item_frameworks = value['type'].split(':')[1]\n",
    "    if item_type in types:\n",
    "        types[item_type]['count'] += 1\n",
    "    else:\n",
    "        types[item_type] = {}\n",
    "        types[item_type]['count'] = 1\n",
    "    if item_type == 'irrelevant':\n",
    "        continue    \n",
    "    for framework, keywords in keywords_dict.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in item_frameworks.lower():\n",
    "                if framework in types[item_type]:\n",
    "                    types[item_type][framework] += 1\n",
    "                else:\n",
    "                    types[item_type][framework] = 1\n",
    "                break\n",
    "    \n",
    "print(f'Original data: {len(datagpt)}')\n",
    "print(f'Filtered data: {len(filtered_datagpt)}')\n",
    "print(types)\n",
    "\n",
    "with open('scrapped_data/types_2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(types, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
